{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aa3e5a1-1ada-4aca-9dcb-6345ff10362e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "\n",
    "import math\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f94317d-b50c-451d-b530-6c230b311aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquiring datasets\n",
      "\n",
      "Done. neighbor_array shape: (198071,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Acquiring datasets\\n\")\n",
    "\n",
    "train_query          = np.load(\"../DatasetCreation/training_dataset.npy\")\n",
    "train_support        = np.load(\"../DatasetCreation/training_support_dataset.npy\")\n",
    "train_query_neighbors= np.load(\"../DatasetCreation/train_query_neighbors.npy\")\n",
    "\n",
    "val_query            = np.load(\"../DatasetCreation/validation_dataset.npy\")\n",
    "val_support          = np.load(\"../DatasetCreation/validation_support_dataset.npy\")\n",
    "val_query_neighbors  = np.load(\"../DatasetCreation/val_query_neighbors.npy\")\n",
    "\n",
    "print(\"Done. neighbor_array shape:\", train_query_neighbors.shape)\n",
    "\n",
    "class TransformerEmbed(nn.Module):\n",
    "    def __init__(self, input_dim=1, d_model=64, nhead=4, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=128,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        \n",
    "        # Remove the pooling layer to maintain temporal resolution\n",
    "        # Instead add a final projection to reduce channel dimension if needed\n",
    "        self.final_proj = nn.Linear(d_model, 32)  # projects each timestep to 32 dimensions\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len=192, 1)\n",
    "        x = self.input_proj(x)              # => (batch, 192, d_model)\n",
    "        x = self.transformer_encoder(x)      # => (batch, 192, d_model)\n",
    "        x = self.final_proj(x)              # => (batch, 192, 32)\n",
    "        return x\n",
    "\n",
    "class SiameseTransformer(nn.Module):\n",
    "    def __init__(self, transformer_model):\n",
    "        super().__init__()\n",
    "        self.transformer = transformer_model\n",
    "        \n",
    "        # Add comparison module to generate richer difference features\n",
    "        self.comparison = nn.Sequential(\n",
    "            nn.Linear(64, 32),  # 64 = concatenated features per timestep\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 32)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        emb1 = self.transformer(x1)  # => (B, 192, 32)\n",
    "        emb2 = self.transformer(x2)  # => (B, 192, 32)\n",
    "        \n",
    "        # Concatenate embeddings along feature dimension\n",
    "        concat_features = torch.cat([emb1, emb2], dim=-1)  # => (B, 192, 64)\n",
    "        \n",
    "        # Generate rich difference features for each timestep\n",
    "        diff = self.comparison(concat_features)  # => (B, 192, 32)\n",
    "        return diff\n",
    "\n",
    "class LSTMForecaster(nn.Module):\n",
    "    def __init__(self, input_dim=1, diff_dim=32, hidden_dim=256, num_layers=3):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Modified to handle sequence of difference vectors\n",
    "        self.diff_encoder = nn.LSTM(\n",
    "            input_size=diff_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Main LSTM now takes concatenated input\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim + hidden_dim,  # Concatenated input and encoded diff\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, support_future, diff_vec):\n",
    "        \"\"\"\n",
    "        support_future: (B, 192, 1)\n",
    "        diff_vec: (B, 192, 32) - now a sequence of difference vectors\n",
    "        => returns (B, 192, 1)\n",
    "        \"\"\"\n",
    "        # Encode the sequence of difference vectors\n",
    "        diff_encoded, (h0, c0) = self.diff_encoder(diff_vec)  # => (B, 192, hidden_dim)\n",
    "        \n",
    "        # Concatenate encoded differences with support_future at each timestep\n",
    "        combined_input = torch.cat([support_future, diff_encoded], dim=-1)  # => (B, 192, input_dim + hidden_dim)\n",
    "        \n",
    "        # Process through main LSTM\n",
    "        lstm_out, _ = self.lstm(combined_input)  # => (B, 192, hidden_dim)\n",
    "        pred = self.fc_out(lstm_out)             # => (B, 192, 1)\n",
    "        \n",
    "        return pred\n",
    "\n",
    "def get_batch(query_dataset, support_dataset, neighbor_array, batch_size):\n",
    "    \"\"\"\n",
    "    neighbor_array: shape (NQ,). neighbor_array[i] gives the best support index for query i\n",
    "    query_dataset, support_dataset: shape (NQ,384) or (NS,384)\n",
    "    \n",
    "    returns x_test, y_test, x_support, y_support as Tensors\n",
    "    \"\"\"\n",
    "    idxs = np.random.choice(len(query_dataset), batch_size, replace=False)\n",
    "\n",
    "    x_test_list = []\n",
    "    y_test_list = []\n",
    "    x_support_list = []\n",
    "    y_support_list = []\n",
    "\n",
    "    for idx in idxs:\n",
    "        chunk = query_dataset[idx]       # shape (384,)\n",
    "        test_past   = chunk[:192]       # shape (192,)\n",
    "        test_future = chunk[192:]       # shape (192,)\n",
    "\n",
    "        # get precomputed support index\n",
    "        idx_support = neighbor_array[idx]\n",
    "        support_chunk = support_dataset[idx_support]\n",
    "        support_past   = support_chunk[:192]\n",
    "        support_future = support_chunk[192:]\n",
    "\n",
    "        x_test_list.append(test_past)\n",
    "        y_test_list.append(test_future)\n",
    "        x_support_list.append(support_past)\n",
    "        y_support_list.append(support_future)\n",
    "\n",
    "    # shape => (B,192)\n",
    "    x_test_arr     = np.array(x_test_list,     dtype=np.float32)\n",
    "    y_test_arr     = np.array(y_test_list,     dtype=np.float32)\n",
    "    x_support_arr  = np.array(x_support_list,  dtype=np.float32)\n",
    "    y_support_arr  = np.array(y_support_list,  dtype=np.float32)\n",
    "\n",
    "    # reshape => (B,192,1)\n",
    "    x_test_tensor     = torch.tensor(x_test_arr).unsqueeze(-1)\n",
    "    y_test_tensor     = torch.tensor(y_test_arr).unsqueeze(-1)\n",
    "    x_support_tensor  = torch.tensor(x_support_arr).unsqueeze(-1)\n",
    "    y_support_tensor  = torch.tensor(y_support_arr).unsqueeze(-1)\n",
    "\n",
    "    return x_test_tensor, y_test_tensor, x_support_tensor, y_support_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25abbd9d-2b3b-4136-970d-5d83628fa37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Initialize models\n",
    "transformer = TransformerEmbed(input_dim=1, d_model=64, nhead=4, num_layers=2)\n",
    "siamese_model = SiameseTransformer(transformer)\n",
    "lstm_model = LSTMForecaster(input_dim=1, diff_dim=32, hidden_dim=256, num_layers=3)\n",
    "\n",
    "# Move models to device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "siamese_model = siamese_model.to(device)\n",
    "lstm_model = lstm_model.to(device)\n",
    "\n",
    "# Loss functions and optimizer\n",
    "criterion_mae = nn.L1Loss()\n",
    "criterion_mse = nn.MSELoss()\n",
    "# Combine parameters from both models for single optimizer\n",
    "params = list(siamese_model.parameters()) + list(lstm_model.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d0cc77-1ee0-47c3-be54-f2caa950ede6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000 - MAE: 782.1811, MSE: 977428.5025\n",
      "Epoch 2/10000 - MAE: 758.7141, MSE: 930934.8784\n",
      "Epoch 3/10000 - MAE: 747.9802, MSE: 906904.1025\n",
      "Epoch 4/10000 - MAE: 703.8657, MSE: 843581.5100\n",
      "Epoch 5/10000 - MAE: 700.0416, MSE: 831013.4894\n",
      "Epoch 6/10000 - MAE: 658.3416, MSE: 767223.3528\n",
      "Epoch 7/10000 - MAE: 650.9808, MSE: 755766.0984\n",
      "Epoch 8/10000 - MAE: 627.2200, MSE: 715999.2659\n",
      "Epoch 9/10000 - MAE: 615.6869, MSE: 693099.8959\n",
      "Epoch 10/10000 - MAE: 585.3372, MSE: 644760.7325\n",
      "Epoch 11/10000 - MAE: 574.7885, MSE: 623367.9153\n",
      "Epoch 12/10000 - MAE: 561.0992, MSE: 602733.3981\n",
      "Epoch 13/10000 - MAE: 554.4943, MSE: 587237.3828\n",
      "Epoch 14/10000 - MAE: 527.5872, MSE: 544356.6859\n",
      "Epoch 15/10000 - MAE: 524.2096, MSE: 535006.6928\n",
      "Epoch 16/10000 - MAE: 496.6518, MSE: 502613.4264\n",
      "Epoch 17/10000 - MAE: 495.7547, MSE: 495423.8000\n",
      "Epoch 18/10000 - MAE: 462.1170, MSE: 444160.3942\n",
      "Epoch 19/10000 - MAE: 447.4118, MSE: 419767.6603\n",
      "Epoch 20/10000 - MAE: 450.1264, MSE: 424104.0656\n",
      "Epoch 21/10000 - MAE: 431.1297, MSE: 392043.0008\n",
      "Epoch 22/10000 - MAE: 409.2413, MSE: 370579.6997\n",
      "Epoch 23/10000 - MAE: 412.8257, MSE: 368681.2353\n",
      "Epoch 24/10000 - MAE: 403.8082, MSE: 352249.9156\n",
      "Epoch 25/10000 - MAE: 392.4189, MSE: 337606.3828\n",
      "Epoch 26/10000 - MAE: 384.2570, MSE: 329012.9459\n",
      "Epoch 27/10000 - MAE: 382.2747, MSE: 323229.5191\n",
      "Epoch 28/10000 - MAE: 360.3473, MSE: 293503.0441\n",
      "Epoch 29/10000 - MAE: 361.2514, MSE: 294938.6701\n",
      "Epoch 30/10000 - MAE: 354.6255, MSE: 283730.9374\n",
      "Epoch 31/10000 - MAE: 340.4827, MSE: 270074.4386\n",
      "Epoch 32/10000 - MAE: 328.4370, MSE: 252861.7892\n",
      "Epoch 33/10000 - MAE: 324.5054, MSE: 248689.0816\n",
      "Epoch 34/10000 - MAE: 327.0717, MSE: 246921.3241\n",
      "Epoch 35/10000 - MAE: 319.8615, MSE: 234936.9162\n",
      "Epoch 36/10000 - MAE: 302.8268, MSE: 219176.1025\n",
      "Epoch 37/10000 - MAE: 308.7723, MSE: 226841.5602\n",
      "Epoch 38/10000 - MAE: 288.8057, MSE: 202538.4388\n",
      "Epoch 39/10000 - MAE: 299.7670, MSE: 216845.5067\n",
      "Epoch 40/10000 - MAE: 278.9979, MSE: 191895.8514\n",
      "Epoch 41/10000 - MAE: 280.1927, MSE: 190917.4505\n",
      "Epoch 42/10000 - MAE: 276.1759, MSE: 184901.9364\n",
      "Epoch 43/10000 - MAE: 272.4911, MSE: 182989.1012\n",
      "Epoch 44/10000 - MAE: 265.1006, MSE: 174131.7473\n",
      "Epoch 45/10000 - MAE: 253.9541, MSE: 160783.6041\n",
      "Epoch 46/10000 - MAE: 255.1141, MSE: 160570.1916\n",
      "Epoch 47/10000 - MAE: 260.1018, MSE: 167562.3408\n",
      "Epoch 48/10000 - MAE: 240.0149, MSE: 148618.5500\n",
      "Epoch 49/10000 - MAE: 241.2788, MSE: 148111.2178\n",
      "Epoch 50/10000 - MAE: 240.3093, MSE: 147763.1396\n",
      "Epoch 51/10000 - MAE: 228.9839, MSE: 136787.4218\n",
      "Epoch 52/10000 - MAE: 232.5796, MSE: 138684.3494\n",
      "Epoch 53/10000 - MAE: 239.9437, MSE: 148576.5551\n",
      "Epoch 54/10000 - MAE: 228.0835, MSE: 134892.3294\n",
      "Epoch 55/10000 - MAE: 220.6632, MSE: 127001.7006\n",
      "Epoch 56/10000 - MAE: 222.7732, MSE: 127963.7061\n",
      "Epoch 57/10000 - MAE: 220.3231, MSE: 125155.8154\n",
      "Epoch 58/10000 - MAE: 211.7043, MSE: 117964.2877\n",
      "Epoch 59/10000 - MAE: 210.2205, MSE: 116004.4255\n",
      "Epoch 60/10000 - MAE: 205.9689, MSE: 113612.9150\n",
      "Epoch 61/10000 - MAE: 204.7024, MSE: 110865.7067\n",
      "Epoch 62/10000 - MAE: 198.1556, MSE: 104275.2138\n",
      "Epoch 63/10000 - MAE: 198.4626, MSE: 103028.4302\n",
      "Epoch 64/10000 - MAE: 203.1160, MSE: 106762.5883\n",
      "Epoch 65/10000 - MAE: 193.8053, MSE: 101533.9033\n",
      "Epoch 66/10000 - MAE: 185.1618, MSE: 91429.0583\n",
      "Epoch 67/10000 - MAE: 192.3819, MSE: 97800.4263\n",
      "Epoch 68/10000 - MAE: 185.2139, MSE: 93194.9659\n",
      "Epoch 69/10000 - MAE: 185.4018, MSE: 93899.9079\n",
      "Epoch 70/10000 - MAE: 181.0695, MSE: 88615.9911\n",
      "Epoch 71/10000 - MAE: 179.0486, MSE: 85599.5846\n",
      "Epoch 72/10000 - MAE: 168.5323, MSE: 79507.3786\n",
      "Epoch 73/10000 - MAE: 166.2531, MSE: 75340.9876\n",
      "Epoch 74/10000 - MAE: 167.7803, MSE: 78350.5683\n",
      "Epoch 75/10000 - MAE: 167.7919, MSE: 76275.9018\n",
      "Epoch 76/10000 - MAE: 157.7498, MSE: 67848.2297\n",
      "Epoch 77/10000 - MAE: 160.4040, MSE: 70093.0786\n",
      "Epoch 78/10000 - MAE: 162.6368, MSE: 71396.0969\n",
      "Epoch 79/10000 - MAE: 155.2989, MSE: 63820.4118\n",
      "Epoch 80/10000 - MAE: 161.1095, MSE: 70523.2596\n",
      "Epoch 81/10000 - MAE: 152.2106, MSE: 63732.7568\n",
      "Epoch 82/10000 - MAE: 150.0423, MSE: 60787.2247\n",
      "Epoch 83/10000 - MAE: 159.1919, MSE: 70997.5368\n",
      "Epoch 84/10000 - MAE: 151.9704, MSE: 63670.5232\n",
      "Epoch 85/10000 - MAE: 145.4169, MSE: 58162.1734\n",
      "Epoch 86/10000 - MAE: 140.9758, MSE: 53766.9271\n",
      "Epoch 87/10000 - MAE: 133.6801, MSE: 49827.6895\n",
      "Epoch 88/10000 - MAE: 145.9240, MSE: 59612.1633\n",
      "Epoch 89/10000 - MAE: 134.8926, MSE: 50118.9828\n",
      "Epoch 90/10000 - MAE: 133.3359, MSE: 48219.9665\n",
      "Epoch 91/10000 - MAE: 130.5544, MSE: 47316.6415\n",
      "Epoch 92/10000 - MAE: 130.6625, MSE: 46732.5640\n",
      "Epoch 93/10000 - MAE: 135.8535, MSE: 53037.1992\n",
      "Epoch 94/10000 - MAE: 126.2000, MSE: 44308.2620\n",
      "Epoch 95/10000 - MAE: 122.4651, MSE: 42008.2628\n",
      "Epoch 96/10000 - MAE: 124.6096, MSE: 41438.0577\n",
      "Epoch 97/10000 - MAE: 123.7567, MSE: 43054.0292\n",
      "Epoch 98/10000 - MAE: 123.3902, MSE: 43335.6489\n",
      "Epoch 99/10000 - MAE: 120.8871, MSE: 41843.0942\n",
      "Epoch 100/10000 - MAE: 118.0643, MSE: 37858.2476\n",
      "Epoch 101/10000 - MAE: 119.0472, MSE: 38806.3144\n",
      "Epoch 102/10000 - MAE: 117.8258, MSE: 37457.9135\n",
      "Epoch 103/10000 - MAE: 117.9958, MSE: 39336.7631\n",
      "Epoch 104/10000 - MAE: 116.7964, MSE: 37303.1227\n",
      "Epoch 105/10000 - MAE: 122.0694, MSE: 41304.9479\n",
      "Epoch 106/10000 - MAE: 120.9090, MSE: 40047.1342\n",
      "Epoch 107/10000 - MAE: 115.5414, MSE: 36638.2498\n"
     ]
    }
   ],
   "source": [
    "# Training constants\n",
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 16\n",
    "STEPS_PER_EPOCH = 100\n",
    "\n",
    "# Setup CSV logging\n",
    "csv_filename = 'training_log.csv'\n",
    "with open(csv_filename, 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"epoch\", \"MAE\", \"MSE\"])\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_mae = 0.0\n",
    "    epoch_mse = 0.0\n",
    "    \n",
    "    for step in range(STEPS_PER_EPOCH):\n",
    "        # Get batch\n",
    "        x_test, y_test, x_support, y_support = get_batch(\n",
    "            query_dataset=train_query,\n",
    "            support_dataset=train_support,\n",
    "            neighbor_array=train_query_neighbors,\n",
    "            batch_size=BATCH_SIZE\n",
    "        )\n",
    "        \n",
    "        # Move to device\n",
    "        x_test = x_test.to(device)\n",
    "        y_test = y_test.to(device)\n",
    "        x_support = x_support.to(device)\n",
    "        y_support = y_support.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Get high-resolution difference vectors\n",
    "        diff_vec = siamese_model(x_test, x_support)  # => (B, 192, 32)\n",
    "        \n",
    "        # Generate forecast\n",
    "        y_pred = lstm_model(y_support, diff_vec)     # => (B, 192, 1)\n",
    "        \n",
    "        # Compute losses\n",
    "        loss_mae = criterion_mae(y_pred, y_test)\n",
    "        loss_mse = criterion_mse(y_pred, y_test)\n",
    "        \n",
    "        # Combined loss for backprop\n",
    "        loss = loss_mae + 0.5 * loss_mse  # weighting can be adjusted\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        # Optional gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(params, max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update metrics\n",
    "        epoch_mae += loss_mae.item()\n",
    "        epoch_mse += loss_mse.item()\n",
    "    \n",
    "    # Compute epoch averages\n",
    "    avg_mae = epoch_mae / STEPS_PER_EPOCH\n",
    "    avg_mse = epoch_mse / STEPS_PER_EPOCH\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} - MAE: {avg_mae:.4f}, MSE: {avg_mse:.4f}\")\n",
    "    \n",
    "    # Log to CSV\n",
    "    with open(csv_filename, 'a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([epoch+1, avg_mae, avg_mse])\n",
    "    \n",
    "    # Save checkpoints every N epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'siamese_state_dict': siamese_model.state_dict(),\n",
    "            'lstm_state_dict': lstm_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'mae': avg_mae,\n",
    "            'mse': avg_mse\n",
    "        }\n",
    "        torch.save(checkpoint, f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff9d35f-8fa0-4551-adf2-282686c44ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
